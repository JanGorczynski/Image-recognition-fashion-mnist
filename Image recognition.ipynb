{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fe57e12",
   "metadata": {},
   "source": [
    "# Importing libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ef0aa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39f07bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69443797",
   "metadata": {},
   "source": [
    "# Basic data exploration\n",
    "The y_train and y_test sginify what type of clothing is on the images in X_train and X_test, numbers in those columns represent:\n",
    "0 T-shirt/top\n",
    "1 Trouser\n",
    "2 Pullover\n",
    "3 Dress\n",
    "4 Coat\n",
    "5 Sandal\n",
    "6 Shirt\n",
    "7 Sneaker\n",
    "8 Bag\n",
    "9 Ankle boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03026e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f88631c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a68b2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0\n",
      "    0   1   4   0   0   0   0   1   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62\n",
      "   54   0   0   0   1   3   4   0   0   3]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134\n",
      "  144 123  23   0   0   0   0  12  10   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178\n",
      "  107 156 161 109  64  23  77 130  72  15]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216\n",
      "  216 163 127 121 122 146 141  88 172  66]\n",
      " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229\n",
      "  223 223 215 213 164 127 123 196 229   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228\n",
      "  235 227 224 222 224 221 223 245 173   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198\n",
      "  180 212 210 211 213 223 220 243 202   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192\n",
      "  169 227 208 218 224 212 226 197 209  52]\n",
      " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203\n",
      "  198 221 215 213 222 220 245 119 167  56]\n",
      " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240\n",
      "  232 213 218 223 234 217 217 209  92   0]\n",
      " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219\n",
      "  222 221 216 223 229 215 218 255  77   0]\n",
      " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208\n",
      "  211 218 224 223 219 215 224 244 159   0]\n",
      " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230\n",
      "  224 234 176 188 250 248 233 238 215   0]\n",
      " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223\n",
      "  255 255 221 234 221 211 220 232 246   0]\n",
      " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221\n",
      "  188 154 191 210 204 209 222 228 225   0]\n",
      " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117\n",
      "  168 219 221 215 217 223 223 224 229  29]\n",
      " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245\n",
      "  239 223 218 212 209 222 220 221 230  67]\n",
      " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216\n",
      "  199 206 186 181 177 172 181 205 206 115]\n",
      " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191\n",
      "  195 191 198 192 176 156 167 177 210  92]\n",
      " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209\n",
      "  210 210 211 188 188 194 192 216 170   0]\n",
      " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179\n",
      "  182 182 181 176 166 168  99  58   0   0]\n",
      " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "749ae841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64a83278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e7cbde",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153bf164",
   "metadata": {},
   "source": [
    "Normalization of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8481d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test/255\n",
    "X_train = X_train/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb27ed1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00392157 0.         0.         0.05098039 0.28627451 0.\n",
      "  0.         0.00392157 0.01568627 0.         0.         0.\n",
      "  0.         0.00392157 0.00392157 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01176471 0.         0.14117647 0.53333333 0.49803922 0.24313725\n",
      "  0.21176471 0.         0.         0.         0.00392157 0.01176471\n",
      "  0.01568627 0.         0.         0.01176471]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.02352941 0.         0.4        0.8        0.69019608 0.5254902\n",
      "  0.56470588 0.48235294 0.09019608 0.         0.         0.\n",
      "  0.         0.04705882 0.03921569 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.60784314 0.9254902  0.81176471 0.69803922\n",
      "  0.41960784 0.61176471 0.63137255 0.42745098 0.25098039 0.09019608\n",
      "  0.30196078 0.50980392 0.28235294 0.05882353]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.00392157\n",
      "  0.         0.27058824 0.81176471 0.8745098  0.85490196 0.84705882\n",
      "  0.84705882 0.63921569 0.49803922 0.4745098  0.47843137 0.57254902\n",
      "  0.55294118 0.34509804 0.6745098  0.25882353]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.00392157 0.00392157 0.00392157\n",
      "  0.         0.78431373 0.90980392 0.90980392 0.91372549 0.89803922\n",
      "  0.8745098  0.8745098  0.84313725 0.83529412 0.64313725 0.49803922\n",
      "  0.48235294 0.76862745 0.89803922 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.71764706 0.88235294 0.84705882 0.8745098  0.89411765\n",
      "  0.92156863 0.89019608 0.87843137 0.87058824 0.87843137 0.86666667\n",
      "  0.8745098  0.96078431 0.67843137 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.75686275 0.89411765 0.85490196 0.83529412 0.77647059\n",
      "  0.70588235 0.83137255 0.82352941 0.82745098 0.83529412 0.8745098\n",
      "  0.8627451  0.95294118 0.79215686 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.00392157 0.01176471 0.\n",
      "  0.04705882 0.85882353 0.8627451  0.83137255 0.85490196 0.75294118\n",
      "  0.6627451  0.89019608 0.81568627 0.85490196 0.87843137 0.83137255\n",
      "  0.88627451 0.77254902 0.81960784 0.20392157]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.02352941 0.\n",
      "  0.38823529 0.95686275 0.87058824 0.8627451  0.85490196 0.79607843\n",
      "  0.77647059 0.86666667 0.84313725 0.83529412 0.87058824 0.8627451\n",
      "  0.96078431 0.46666667 0.65490196 0.21960784]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.01568627 0.         0.\n",
      "  0.21568627 0.9254902  0.89411765 0.90196078 0.89411765 0.94117647\n",
      "  0.90980392 0.83529412 0.85490196 0.8745098  0.91764706 0.85098039\n",
      "  0.85098039 0.81960784 0.36078431 0.        ]\n",
      " [0.         0.         0.00392157 0.01568627 0.02352941 0.02745098\n",
      "  0.00784314 0.         0.         0.         0.         0.\n",
      "  0.92941176 0.88627451 0.85098039 0.8745098  0.87058824 0.85882353\n",
      "  0.87058824 0.86666667 0.84705882 0.8745098  0.89803922 0.84313725\n",
      "  0.85490196 1.         0.30196078 0.        ]\n",
      " [0.         0.01176471 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.24313725 0.56862745 0.8\n",
      "  0.89411765 0.81176471 0.83529412 0.86666667 0.85490196 0.81568627\n",
      "  0.82745098 0.85490196 0.87843137 0.8745098  0.85882353 0.84313725\n",
      "  0.87843137 0.95686275 0.62352941 0.        ]\n",
      " [0.         0.         0.         0.         0.07058824 0.17254902\n",
      "  0.32156863 0.41960784 0.74117647 0.89411765 0.8627451  0.87058824\n",
      "  0.85098039 0.88627451 0.78431373 0.80392157 0.82745098 0.90196078\n",
      "  0.87843137 0.91764706 0.69019608 0.7372549  0.98039216 0.97254902\n",
      "  0.91372549 0.93333333 0.84313725 0.        ]\n",
      " [0.         0.22352941 0.73333333 0.81568627 0.87843137 0.86666667\n",
      "  0.87843137 0.81568627 0.8        0.83921569 0.81568627 0.81960784\n",
      "  0.78431373 0.62352941 0.96078431 0.75686275 0.80784314 0.8745098\n",
      "  1.         1.         0.86666667 0.91764706 0.86666667 0.82745098\n",
      "  0.8627451  0.90980392 0.96470588 0.        ]\n",
      " [0.01176471 0.79215686 0.89411765 0.87843137 0.86666667 0.82745098\n",
      "  0.82745098 0.83921569 0.80392157 0.80392157 0.80392157 0.8627451\n",
      "  0.94117647 0.31372549 0.58823529 1.         0.89803922 0.86666667\n",
      "  0.7372549  0.60392157 0.74901961 0.82352941 0.8        0.81960784\n",
      "  0.87058824 0.89411765 0.88235294 0.        ]\n",
      " [0.38431373 0.91372549 0.77647059 0.82352941 0.87058824 0.89803922\n",
      "  0.89803922 0.91764706 0.97647059 0.8627451  0.76078431 0.84313725\n",
      "  0.85098039 0.94509804 0.25490196 0.28627451 0.41568627 0.45882353\n",
      "  0.65882353 0.85882353 0.86666667 0.84313725 0.85098039 0.8745098\n",
      "  0.8745098  0.87843137 0.89803922 0.11372549]\n",
      " [0.29411765 0.8        0.83137255 0.8        0.75686275 0.80392157\n",
      "  0.82745098 0.88235294 0.84705882 0.7254902  0.77254902 0.80784314\n",
      "  0.77647059 0.83529412 0.94117647 0.76470588 0.89019608 0.96078431\n",
      "  0.9372549  0.8745098  0.85490196 0.83137255 0.81960784 0.87058824\n",
      "  0.8627451  0.86666667 0.90196078 0.2627451 ]\n",
      " [0.18823529 0.79607843 0.71764706 0.76078431 0.83529412 0.77254902\n",
      "  0.7254902  0.74509804 0.76078431 0.75294118 0.79215686 0.83921569\n",
      "  0.85882353 0.86666667 0.8627451  0.9254902  0.88235294 0.84705882\n",
      "  0.78039216 0.80784314 0.72941176 0.70980392 0.69411765 0.6745098\n",
      "  0.70980392 0.80392157 0.80784314 0.45098039]\n",
      " [0.         0.47843137 0.85882353 0.75686275 0.70196078 0.67058824\n",
      "  0.71764706 0.76862745 0.8        0.82352941 0.83529412 0.81176471\n",
      "  0.82745098 0.82352941 0.78431373 0.76862745 0.76078431 0.74901961\n",
      "  0.76470588 0.74901961 0.77647059 0.75294118 0.69019608 0.61176471\n",
      "  0.65490196 0.69411765 0.82352941 0.36078431]\n",
      " [0.         0.         0.29019608 0.74117647 0.83137255 0.74901961\n",
      "  0.68627451 0.6745098  0.68627451 0.70980392 0.7254902  0.7372549\n",
      "  0.74117647 0.7372549  0.75686275 0.77647059 0.8        0.81960784\n",
      "  0.82352941 0.82352941 0.82745098 0.7372549  0.7372549  0.76078431\n",
      "  0.75294118 0.84705882 0.66666667 0.        ]\n",
      " [0.00784314 0.         0.         0.         0.25882353 0.78431373\n",
      "  0.87058824 0.92941176 0.9372549  0.94901961 0.96470588 0.95294118\n",
      "  0.95686275 0.86666667 0.8627451  0.75686275 0.74901961 0.70196078\n",
      "  0.71372549 0.71372549 0.70980392 0.69019608 0.65098039 0.65882353\n",
      "  0.38823529 0.22745098 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.15686275 0.23921569 0.17254902 0.28235294 0.16078431\n",
      "  0.1372549  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "363f3c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1889c8b2",
   "metadata": {},
   "source": [
    "Now we flatten the image, so that in can be inputed to neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea554735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02b63c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91c9a188",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flat = X_train.reshape(60000,784)\n",
    "X_test_flat = X_test.reshape(10000,784)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e738dd6",
   "metadata": {},
   "source": [
    "Now we need to one code the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32941b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T-shirt/top</th>\n",
       "      <th>Trouser</th>\n",
       "      <th>Pullover</th>\n",
       "      <th>Dress</th>\n",
       "      <th>Coat</th>\n",
       "      <th>Sandal</th>\n",
       "      <th>Shirt</th>\n",
       "      <th>Sneaker</th>\n",
       "      <th>Bag</th>\n",
       "      <th>Ankle_boot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   T-shirt/top  Trouser  Pullover  Dress  Coat  Sandal  Shirt  Sneaker  Bag  \\\n",
       "0            0        0         0      0     0       0      0        0    0   \n",
       "1            1        0         0      0     0       0      0        0    0   \n",
       "2            1        0         0      0     0       0      0        0    0   \n",
       "3            0        0         0      1     0       0      0        0    0   \n",
       "4            1        0         0      0     0       0      0        0    0   \n",
       "\n",
       "   Ankle_boot  \n",
       "0           1  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = pd.get_dummies(y_train)\n",
    "y_train.columns = [\"T-shirt/top\",\"Trouser\",\"Pullover\", \"Dress\", \"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\" ,\"Ankle_boot\"]\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58102641",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T-shirt/top</th>\n",
       "      <th>Trouser</th>\n",
       "      <th>Pullover</th>\n",
       "      <th>Dress</th>\n",
       "      <th>Coat</th>\n",
       "      <th>Sandal</th>\n",
       "      <th>Shirt</th>\n",
       "      <th>Sneaker</th>\n",
       "      <th>Bag</th>\n",
       "      <th>Ankle_boot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   T-shirt/top  Trouser  Pullover  Dress  Coat  Sandal  Shirt  Sneaker  Bag  \\\n",
       "0            0        0         0      0     0       0      0        0    0   \n",
       "1            0        0         1      0     0       0      0        0    0   \n",
       "2            0        1         0      0     0       0      0        0    0   \n",
       "3            0        1         0      0     0       0      0        0    0   \n",
       "4            0        0         0      0     0       0      1        0    0   \n",
       "\n",
       "   Ankle_boot  \n",
       "0           1  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = pd.get_dummies(y_test)\n",
    "y_test.columns = [\"T-shirt/top\",\"Trouser\",\"Pullover\", \"Dress\", \"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\" ,\"Ankle_boot\"]\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5308a9",
   "metadata": {},
   "source": [
    "# Basic neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff9ce97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout,InputLayer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1585ad",
   "metadata": {},
   "source": [
    "First model, rectified linear unit as activation function, one dropout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "917aa8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(InputLayer(784))\n",
    "model1.add(Dense(128,activation = \"relu\"))\n",
    "model1.add(Dense(128,activation = \"relu\"))\n",
    "model1.add(Dense(128,activation = \"relu\"))\n",
    "model1.add(Dropout(0.3))\n",
    "\n",
    "model1.add(Dense(units=10, activation='softmax'))\n",
    "model1.compile(loss= \"CategoricalCrossentropy\",optimizer = Adam(learning_rate=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "696e5000",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.5743 - accuracy: 0.7969 - val_loss: 0.4085 - val_accuracy: 0.8524\n",
      "Epoch 2/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.3909 - accuracy: 0.8593 - val_loss: 0.3422 - val_accuracy: 0.8742\n",
      "Epoch 3/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.3509 - accuracy: 0.8735 - val_loss: 0.3077 - val_accuracy: 0.8874\n",
      "Epoch 4/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.3263 - accuracy: 0.8802 - val_loss: 0.2971 - val_accuracy: 0.8889\n",
      "Epoch 5/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.3076 - accuracy: 0.8865 - val_loss: 0.2790 - val_accuracy: 0.8961\n",
      "Epoch 6/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2915 - accuracy: 0.8939 - val_loss: 0.2687 - val_accuracy: 0.8965\n",
      "Epoch 7/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2813 - accuracy: 0.8954 - val_loss: 0.2633 - val_accuracy: 0.9003\n",
      "Epoch 8/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2678 - accuracy: 0.9008 - val_loss: 0.2343 - val_accuracy: 0.9120\n",
      "Epoch 9/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2604 - accuracy: 0.9018 - val_loss: 0.2331 - val_accuracy: 0.9109\n",
      "Epoch 10/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2502 - accuracy: 0.9068 - val_loss: 0.2462 - val_accuracy: 0.9048\n",
      "Epoch 11/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2447 - accuracy: 0.9086 - val_loss: 0.2312 - val_accuracy: 0.9132\n",
      "Epoch 12/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2347 - accuracy: 0.9124 - val_loss: 0.2257 - val_accuracy: 0.9159\n",
      "Epoch 13/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2265 - accuracy: 0.9155 - val_loss: 0.2075 - val_accuracy: 0.9226\n",
      "Epoch 14/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2230 - accuracy: 0.9152 - val_loss: 0.2142 - val_accuracy: 0.9176\n",
      "Epoch 15/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2131 - accuracy: 0.9198 - val_loss: 0.1849 - val_accuracy: 0.9290\n",
      "Epoch 16/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2099 - accuracy: 0.9204 - val_loss: 0.1837 - val_accuracy: 0.9299\n",
      "Epoch 17/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2030 - accuracy: 0.9242 - val_loss: 0.1797 - val_accuracy: 0.9316\n",
      "Epoch 18/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1952 - accuracy: 0.9256 - val_loss: 0.1760 - val_accuracy: 0.9333\n",
      "Epoch 19/50\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1923 - accuracy: 0.9263 - val_loss: 0.1604 - val_accuracy: 0.9390\n",
      "Epoch 20/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1884 - accuracy: 0.9280 - val_loss: 0.1631 - val_accuracy: 0.9379\n",
      "Epoch 21/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1810 - accuracy: 0.9311 - val_loss: 0.1614 - val_accuracy: 0.9375\n",
      "Epoch 22/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1749 - accuracy: 0.9337 - val_loss: 0.1641 - val_accuracy: 0.9367\n",
      "Epoch 23/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1764 - accuracy: 0.9335 - val_loss: 0.1467 - val_accuracy: 0.9432\n",
      "Epoch 24/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1714 - accuracy: 0.9335 - val_loss: 0.1414 - val_accuracy: 0.9455\n",
      "Epoch 25/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1641 - accuracy: 0.9370 - val_loss: 0.1457 - val_accuracy: 0.9431\n",
      "Epoch 26/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1594 - accuracy: 0.9388 - val_loss: 0.1386 - val_accuracy: 0.9453\n",
      "Epoch 27/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1588 - accuracy: 0.9391 - val_loss: 0.1335 - val_accuracy: 0.9470\n",
      "Epoch 28/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1556 - accuracy: 0.9393 - val_loss: 0.1282 - val_accuracy: 0.9496\n",
      "Epoch 29/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1530 - accuracy: 0.9417 - val_loss: 0.1434 - val_accuracy: 0.9456\n",
      "Epoch 30/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1463 - accuracy: 0.9426 - val_loss: 0.1273 - val_accuracy: 0.9503\n",
      "Epoch 31/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1431 - accuracy: 0.9448 - val_loss: 0.1265 - val_accuracy: 0.9497\n",
      "Epoch 32/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1389 - accuracy: 0.9462 - val_loss: 0.1299 - val_accuracy: 0.9473\n",
      "Epoch 33/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1351 - accuracy: 0.9474 - val_loss: 0.1165 - val_accuracy: 0.9532\n",
      "Epoch 34/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1308 - accuracy: 0.9481 - val_loss: 0.1114 - val_accuracy: 0.9574\n",
      "Epoch 35/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1269 - accuracy: 0.9503 - val_loss: 0.1014 - val_accuracy: 0.9598\n",
      "Epoch 36/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1309 - accuracy: 0.9490 - val_loss: 0.1165 - val_accuracy: 0.9552\n",
      "Epoch 37/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1229 - accuracy: 0.9523 - val_loss: 0.1072 - val_accuracy: 0.9577\n",
      "Epoch 38/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1235 - accuracy: 0.9513 - val_loss: 0.1048 - val_accuracy: 0.9571\n",
      "Epoch 39/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1219 - accuracy: 0.9534 - val_loss: 0.0984 - val_accuracy: 0.9612\n",
      "Epoch 40/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1168 - accuracy: 0.9543 - val_loss: 0.1027 - val_accuracy: 0.9589\n",
      "Epoch 41/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1146 - accuracy: 0.9552 - val_loss: 0.0970 - val_accuracy: 0.9626\n",
      "Epoch 42/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1116 - accuracy: 0.9563 - val_loss: 0.0989 - val_accuracy: 0.9610\n",
      "Epoch 43/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1128 - accuracy: 0.9558 - val_loss: 0.0912 - val_accuracy: 0.9616\n",
      "Epoch 44/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1095 - accuracy: 0.9570 - val_loss: 0.0983 - val_accuracy: 0.9615\n",
      "Epoch 45/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1098 - accuracy: 0.9565 - val_loss: 0.0908 - val_accuracy: 0.9650\n",
      "Epoch 46/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1025 - accuracy: 0.9596 - val_loss: 0.0941 - val_accuracy: 0.9613\n",
      "Epoch 47/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1050 - accuracy: 0.9585 - val_loss: 0.0760 - val_accuracy: 0.9693\n",
      "Epoch 48/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1033 - accuracy: 0.9589 - val_loss: 0.0997 - val_accuracy: 0.9591\n",
      "Epoch 49/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0958 - accuracy: 0.9617 - val_loss: 0.0923 - val_accuracy: 0.9623\n",
      "Epoch 50/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0979 - accuracy: 0.9612 - val_loss: 0.0803 - val_accuracy: 0.9682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x207a42d0970>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train_flat, y_train, batch_size=128, epochs=50, verbose=1,validation_data=(X_train_flat, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f578cf6",
   "metadata": {},
   "source": [
    "Making predictions, and converting to categorical values from propability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bdd2c079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model1.predict(X_test_flat)\n",
    "for  index,prediction_vector in enumerate(predictions):\n",
    "    max_index = np.argmax(prediction_vector)\n",
    "    predictions[index] = np.zeros(len(prediction_vector))\n",
    "    predictions[index][max_index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9597e0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84       936\n",
      "           1       0.98      0.98      0.98       994\n",
      "           2       0.82      0.82      0.82       996\n",
      "           3       0.91      0.88      0.89      1031\n",
      "           4       0.84      0.81      0.83      1039\n",
      "           5       0.96      0.98      0.97       977\n",
      "           6       0.72      0.73      0.72       991\n",
      "           7       0.97      0.95      0.96      1028\n",
      "           8       0.98      0.97      0.97      1010\n",
      "           9       0.96      0.96      0.96       998\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      " samples avg       0.90      0.90      0.90     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51333d13",
   "metadata": {},
   "source": [
    "Secound model tanh as activation function, one dropout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd32a1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(InputLayer(784))\n",
    "model2.add(Dense(128,activation = \"tanh\"))\n",
    "model2.add(Dense(128,activation = \"tanh\"))\n",
    "model2.add(Dense(128,activation = \"tanh\"))\n",
    "model2.add(Dropout(0.3))\n",
    "\n",
    "model2.add(Dense(units=10, activation='softmax'))\n",
    "model2.compile(loss= \"CategoricalCrossentropy\",optimizer = Adam(learning_rate=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eaf2cc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.5398 - accuracy: 0.8062 - val_loss: 0.4389 - val_accuracy: 0.8346\n",
      "Epoch 2/50\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.4003 - accuracy: 0.8557 - val_loss: 0.3641 - val_accuracy: 0.8659\n",
      "Epoch 3/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.3626 - accuracy: 0.8688 - val_loss: 0.3131 - val_accuracy: 0.8857\n",
      "Epoch 4/50\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.3368 - accuracy: 0.8770 - val_loss: 0.3191 - val_accuracy: 0.8820\n",
      "Epoch 5/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.3204 - accuracy: 0.8836 - val_loss: 0.3173 - val_accuracy: 0.8819\n",
      "Epoch 6/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.3021 - accuracy: 0.8896 - val_loss: 0.2712 - val_accuracy: 0.8999\n",
      "Epoch 7/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2926 - accuracy: 0.8925 - val_loss: 0.2711 - val_accuracy: 0.9010\n",
      "Epoch 8/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2809 - accuracy: 0.8961 - val_loss: 0.2619 - val_accuracy: 0.9039\n",
      "Epoch 9/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2714 - accuracy: 0.9015 - val_loss: 0.2418 - val_accuracy: 0.9100\n",
      "Epoch 10/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2624 - accuracy: 0.9013 - val_loss: 0.2495 - val_accuracy: 0.9055\n",
      "Epoch 11/50\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.2514 - accuracy: 0.9076 - val_loss: 0.2417 - val_accuracy: 0.9093\n",
      "Epoch 12/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2443 - accuracy: 0.9103 - val_loss: 0.2188 - val_accuracy: 0.9187\n",
      "Epoch 13/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2379 - accuracy: 0.9115 - val_loss: 0.2235 - val_accuracy: 0.9162\n",
      "Epoch 14/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2312 - accuracy: 0.9143 - val_loss: 0.2190 - val_accuracy: 0.9181\n",
      "Epoch 15/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2244 - accuracy: 0.9173 - val_loss: 0.1948 - val_accuracy: 0.9279\n",
      "Epoch 16/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2182 - accuracy: 0.9195 - val_loss: 0.1962 - val_accuracy: 0.9270\n",
      "Epoch 17/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2108 - accuracy: 0.9218 - val_loss: 0.1849 - val_accuracy: 0.9316\n",
      "Epoch 18/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2079 - accuracy: 0.9222 - val_loss: 0.1973 - val_accuracy: 0.9256\n",
      "Epoch 19/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2029 - accuracy: 0.9243 - val_loss: 0.2042 - val_accuracy: 0.9228\n",
      "Epoch 20/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1949 - accuracy: 0.9267 - val_loss: 0.1783 - val_accuracy: 0.9335\n",
      "Epoch 21/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1894 - accuracy: 0.9292 - val_loss: 0.1765 - val_accuracy: 0.9346\n",
      "Epoch 22/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1836 - accuracy: 0.9315 - val_loss: 0.1591 - val_accuracy: 0.9405\n",
      "Epoch 23/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1810 - accuracy: 0.9335 - val_loss: 0.1553 - val_accuracy: 0.9415\n",
      "Epoch 24/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1746 - accuracy: 0.9348 - val_loss: 0.1427 - val_accuracy: 0.9477\n",
      "Epoch 25/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1689 - accuracy: 0.9371 - val_loss: 0.1420 - val_accuracy: 0.9488\n",
      "Epoch 26/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1663 - accuracy: 0.9379 - val_loss: 0.1378 - val_accuracy: 0.9482\n",
      "Epoch 27/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1652 - accuracy: 0.9378 - val_loss: 0.1510 - val_accuracy: 0.9434\n",
      "Epoch 28/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1545 - accuracy: 0.9420 - val_loss: 0.1379 - val_accuracy: 0.9504\n",
      "Epoch 29/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1570 - accuracy: 0.9422 - val_loss: 0.1297 - val_accuracy: 0.9537\n",
      "Epoch 30/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1486 - accuracy: 0.9446 - val_loss: 0.1367 - val_accuracy: 0.9492\n",
      "Epoch 31/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1476 - accuracy: 0.9452 - val_loss: 0.1441 - val_accuracy: 0.9461\n",
      "Epoch 32/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1441 - accuracy: 0.9476 - val_loss: 0.1357 - val_accuracy: 0.9492\n",
      "Epoch 33/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1392 - accuracy: 0.9486 - val_loss: 0.1221 - val_accuracy: 0.9557\n",
      "Epoch 34/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1357 - accuracy: 0.9496 - val_loss: 0.1166 - val_accuracy: 0.9584\n",
      "Epoch 35/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1326 - accuracy: 0.9517 - val_loss: 0.1098 - val_accuracy: 0.9598\n",
      "Epoch 36/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1313 - accuracy: 0.9512 - val_loss: 0.1069 - val_accuracy: 0.9607\n",
      "Epoch 37/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1252 - accuracy: 0.9544 - val_loss: 0.1125 - val_accuracy: 0.9581\n",
      "Epoch 38/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1218 - accuracy: 0.9550 - val_loss: 0.1146 - val_accuracy: 0.9568\n",
      "Epoch 39/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1201 - accuracy: 0.9551 - val_loss: 0.1496 - val_accuracy: 0.9406\n",
      "Epoch 40/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1158 - accuracy: 0.9580 - val_loss: 0.1049 - val_accuracy: 0.9617\n",
      "Epoch 41/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1089 - accuracy: 0.9605 - val_loss: 0.1123 - val_accuracy: 0.9578\n",
      "Epoch 42/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1109 - accuracy: 0.9589 - val_loss: 0.0978 - val_accuracy: 0.9634\n",
      "Epoch 43/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1050 - accuracy: 0.9610 - val_loss: 0.0996 - val_accuracy: 0.9629\n",
      "Epoch 44/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1036 - accuracy: 0.9626 - val_loss: 0.0808 - val_accuracy: 0.9718\n",
      "Epoch 45/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1010 - accuracy: 0.9632 - val_loss: 0.0830 - val_accuracy: 0.9711\n",
      "Epoch 46/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0985 - accuracy: 0.9635 - val_loss: 0.1071 - val_accuracy: 0.9614\n",
      "Epoch 47/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0944 - accuracy: 0.9654 - val_loss: 0.0738 - val_accuracy: 0.9737\n",
      "Epoch 48/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0956 - accuracy: 0.9649 - val_loss: 0.1015 - val_accuracy: 0.9628\n",
      "Epoch 49/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0944 - accuracy: 0.9655 - val_loss: 0.0811 - val_accuracy: 0.9711\n",
      "Epoch 50/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0926 - accuracy: 0.9655 - val_loss: 0.0701 - val_accuracy: 0.9758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x207a13f83d0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train_flat, y_train, batch_size=128, epochs=50, verbose=1,validation_data=(X_train_flat, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5bc6d730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model1.predict(X_test_flat)\n",
    "for  index,prediction_vector in enumerate(predictions):\n",
    "    max_index = np.argmax(prediction_vector)\n",
    "    predictions[index] = np.zeros(len(prediction_vector))\n",
    "    predictions[index][max_index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7cd6043e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84       936\n",
      "           1       0.98      0.98      0.98       994\n",
      "           2       0.82      0.82      0.82       996\n",
      "           3       0.91      0.88      0.89      1031\n",
      "           4       0.84      0.81      0.83      1039\n",
      "           5       0.96      0.98      0.97       977\n",
      "           6       0.72      0.73      0.72       991\n",
      "           7       0.97      0.95      0.96      1028\n",
      "           8       0.98      0.97      0.97      1010\n",
      "           9       0.96      0.96      0.96       998\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      " samples avg       0.90      0.90      0.90     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3afc92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
